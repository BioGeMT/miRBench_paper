{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T6BIHgU38o2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 12:00:50.725484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 12:00:52.471753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from tensorflow.keras.layers import (\n",
    "                                BatchNormalization, LeakyReLU,\n",
    "                                Input, Dense, Conv2D,\n",
    "                                MaxPooling2D, Flatten, Dropout)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random state for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "K.utils.set_random_seed(42)\n",
    "# still not reproducible? why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATIO = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CpoytQwIElkg"
   },
   "outputs": [],
   "source": [
    "def make_architecture():\n",
    "    \"\"\"\n",
    "    build model architecture\n",
    "\n",
    "    return a model object\n",
    "    \"\"\"\n",
    "    cnn_num = 6\n",
    "    kernel_size = 5\n",
    "    pool_size = 2\n",
    "    dropout_rate = 0.3\n",
    "    dense_num = 2\n",
    "\n",
    "    x = Input(shape=(50,20,1),\n",
    "                       dtype='float32', name='main_input'\n",
    "                       )\n",
    "    main_input = x\n",
    "\n",
    "    for cnn_i in range(cnn_num):\n",
    "        x = Conv2D(\n",
    "            filters=32 * (cnn_i + 1),\n",
    "            kernel_size=(kernel_size, kernel_size),\n",
    "            padding=\"same\",\n",
    "            data_format=\"channels_last\",\n",
    "            name=\"conv_\" + str(cnn_i + 1))(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(pool_size, pool_size), padding='same', name='Max_' + str(cnn_i + 1))(x)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    x = Flatten(name='2d_matrix')(x)\n",
    "\n",
    "    for dense_i in range(dense_num):\n",
    "        neurons = 32 * (cnn_num - dense_i)\n",
    "        x = Dense(neurons)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "    m = K.Model(inputs=[main_input], outputs=[main_output], name='arch_00')\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oZ591qC0Femi"
   },
   "outputs": [],
   "source": [
    "def compile_model():\n",
    "    K.backend.clear_session()\n",
    "    m = make_architecture()\n",
    "    \n",
    "    opt = Adam(\n",
    "        learning_rate=0.00152,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        amsgrad=False,\n",
    "        name=\"Adam\")\n",
    "\n",
    "    m.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wTB6K0lxyzcx"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    plot history of the model training,\n",
    "    accuracy and loss of the training and validation set\n",
    "    \"\"\"\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"training_acc_1_{RATIO}.jpg\")\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"training_loss_1_{RATIO}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, data_path, labels_path, batch_size, validation_split=0.1, is_validation=False, shuffle=True):\n",
    "        # preload the encoded numpy data\n",
    "        # the size needed to properly load the array\n",
    "        self.size = 0\n",
    "        if RATIO == 1:\n",
    "            self.size = 2524246\n",
    "        elif RATIO == 10:\n",
    "            self.size = 13883353\n",
    "        elif RATIO == 100:\n",
    "            self.size = 127476014\n",
    "            \n",
    "        self.data = np.memmap(data_path, dtype='float32', mode='r', shape=(self.size, 50, 20, 1))\n",
    "        self.labels = np.memmap(labels_path, dtype='float32', mode='r', shape=(self.size,))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        # Determine number of train and validation samples\n",
    "        self.validation_split = validation_split\n",
    "        self.num_samples = len(self.data)\n",
    "        self.num_validation_samples = int(self.num_samples * validation_split)\n",
    "        self.num_train_samples = self.num_samples - self.num_validation_samples\n",
    "        \n",
    "        # Determine indices for validation and training\n",
    "        indices = np.arange(self.num_samples)\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        \n",
    "        if is_validation:\n",
    "            self.indices = indices[self.num_train_samples:]\n",
    "        else:\n",
    "            self.indices = indices[:self.num_train_samples]\n",
    "        \n",
    "        # Shuffle the data initially\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return int(np.ceil(len(self.indices) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate one batch of data\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_data = self.data[batch_indices]\n",
    "        batch_labels = self.labels[batch_indices]\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Updates indices after each epoch for shuffling\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = DataGenerator(f\"Manakov2022_{RATIO}_train_dataset.npy\", f\"Manakov2022_{RATIO}_train_labels.npy\", batch_size=32, validation_split=0.1, is_validation=False)\n",
    "\n",
    "val_data_gen = DataGenerator(f\"Manakov2022_{RATIO}_train_dataset.npy\", f\"Manakov2022_{RATIO}_train_labels.npy\", batch_size=32, validation_split=0.1, is_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lcc6OuabyVsK",
    "outputId": "bb4e3fae-f08d-4d37-acfe-ff41c66e83eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"arch_00\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " main_input (InputLayer)     [(None, 50, 20, 1)]       0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 50, 20, 32)        832       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 50, 20, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 50, 20, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " Max_1 (MaxPooling2D)        (None, 25, 10, 32)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 10, 32)        0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 25, 10, 64)        51264     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 25, 10, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 25, 10, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 12:01:27.585010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43440 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:27:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Max_2 (MaxPooling2D)        (None, 13, 5, 64)         0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 5, 64)         0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 13, 5, 96)         153696    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 13, 5, 96)         0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 13, 5, 96)         384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " Max_3 (MaxPooling2D)        (None, 7, 3, 96)          0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 3, 96)          0         \n",
      "                                                                 \n",
      " conv_4 (Conv2D)             (None, 7, 3, 128)         307328    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 7, 3, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 7, 3, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " Max_4 (MaxPooling2D)        (None, 4, 2, 128)         0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 2, 128)         0         \n",
      "                                                                 \n",
      " conv_5 (Conv2D)             (None, 4, 2, 160)         512160    \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 4, 2, 160)         0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 4, 2, 160)         640       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " Max_5 (MaxPooling2D)        (None, 2, 1, 160)         0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2, 1, 160)         0         \n",
      "                                                                 \n",
      " conv_6 (Conv2D)             (None, 2, 1, 192)         768192    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 2, 1, 192)         0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 2, 1, 192)         768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " Max_6 (MaxPooling2D)        (None, 1, 1, 192)         0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, 1, 192)         0         \n",
      "                                                                 \n",
      " 2d_matrix (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 192)               37056     \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 192)               0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 192)               768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 160)               30880     \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 160)               0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 160)               640       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 160)               0         \n",
      "                                                                 \n",
      " main_output (Dense)         (None, 1)                 161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1865665 (7.12 MB)\n",
      "Trainable params: 1863617 (7.11 MB)\n",
      "Non-trainable params: 2048 (8.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = compile_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIEbdJxqydNm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 12:01:36.237326: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inarch_00/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-09 12:01:38.567416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "2024-08-09 12:01:38.856255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-08-09 12:01:38.902920: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aa14cdd7c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-09 12:01:38.902962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2024-08-09 12:01:38.909208: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-09 12:01:39.028003: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 202449/3585263 [>.............................] - ETA: 34:32:55 - loss: 0.4993 - accuracy: 0.9040"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(\n",
    "    train_data_gen,\n",
    "    validation_data=val_data_gen,\n",
    "    epochs=10,\n",
    "    class_weight={0: 1, 1: RATIO}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4uUTu-k0Y2S"
   },
   "outputs": [],
   "source": [
    "plot_history(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"model_Manakov22_{RATIO}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:miRBench2]",
   "language": "python",
   "name": "conda-env-miRBench2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
